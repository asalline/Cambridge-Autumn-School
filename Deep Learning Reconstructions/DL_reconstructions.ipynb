{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image reconstructions with deep learning \n",
    "\n",
    "In this notebook one can see what kind of results three different deep neural networks algorithms give when trained to reconstruct images. <br>\n",
    "The three algorithms are FBP with U-Net denoising, Learned Gradient Scheme (LGS) and Learned Primal-Dual (LPD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import torch\n",
    "import odl\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from odl.contrib.torch import OperatorModule\n",
    "from FBP_UNet_module import UNet\n",
    "from LGS_module import LGS\n",
    "from LPD_module import LPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next one needs to get image(s) which to use ODL to get sinograms and add noise to them. <br>\n",
    "There is alot of ways to get images but here is one, feel free to change the next part if you know some better way. <br>\n",
    "Just be careful to not change images' data type or anything if not sure it will work. <br>\n",
    "The function below either gives you all the images from the directory or just $n$ amount of random images. <br>\n",
    "#### Images are scaled for a reason that the training would go quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(path, amount_of_images='all', scale_number=1):\n",
    "\n",
    "    all_images = []\n",
    "    all_image_names = os.listdir(path)\n",
    "    print(len(all_image_names))\n",
    "    if amount_of_images == 'all':\n",
    "        for name in all_image_names:\n",
    "            temp_image = cv.imread(path + '/' + name, cv.IMREAD_UNCHANGED)\n",
    "            image = temp_image[90:410, 90:410]\n",
    "            image = image[0:320:scale_number, 0:320:scale_number]\n",
    "            image = image / 0.07584485627272729\n",
    "            all_images.append(image)\n",
    "    else:\n",
    "        temp_indexing = np.random.permutation(len(all_image_names))[:amount_of_images]\n",
    "        \n",
    "        images_to_take = [all_image_names[i] for i in temp_indexing]\n",
    "        for name in images_to_take:\n",
    "            temp_image = cv.imread(path + '/' + name, cv.IMREAD_UNCHANGED)\n",
    "            image = temp_image[90:410, 90:410]\n",
    "            image = image[0:320:scale_number, 0:320:scale_number]\n",
    "            image = image / 0.07584485627272729\n",
    "            all_images.append(image)\n",
    "    \n",
    "    return all_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is to define the function for ODL geometry and Ray transform. It is the same as in classical algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometry_and_ray_trafo(setup='full', min_domain_corner=[-1,-1], max_domain_corner=[1,1], \\\n",
    "                           shape=(100,100), source_radius=2, detector_radius=1, \\\n",
    "                           dtype='float32', device='cpu', factor_lines = 1):\n",
    "\n",
    "    device = 'astra_' + device\n",
    "    print(device)\n",
    "    domain = odl.uniform_discr(min_domain_corner, max_domain_corner, shape, dtype=dtype)\n",
    "\n",
    "    if setup == 'full':\n",
    "        angles = odl.uniform_partition(0, 2*np.pi, 360)\n",
    "        lines = odl.uniform_partition(-1*np.pi, np.pi, int(1028/factor_lines))\n",
    "        geometry = odl.tomo.FanBeamGeometry(angles, lines, source_radius, detector_radius)\n",
    "        output_shape = (360, int(1028/factor_lines))\n",
    "    elif setup == 'sparse':\n",
    "        angle_measurements = 100\n",
    "        line_measurements = int(512/factor_lines)\n",
    "        angles = odl.uniform_partition(0, 2*np.pi, angle_measurements)\n",
    "        lines = odl.uniform_partition(-1*np.pi, np.pi, line_measurements)\n",
    "        geometry = odl.tomo.FanBeamGeometry(angles, lines, source_radius, detector_radius)\n",
    "        output_shape = (angle_measurements, line_measurements)\n",
    "    elif setup == 'limited':\n",
    "        starting_angle = 0\n",
    "        final_angle = np.pi * 3/4\n",
    "        angles = odl.uniform_partition(starting_angle, final_angle, 360)\n",
    "        lines = odl.uniform_partition(-1*np.pi, np.pi, int(512/factor_lines))\n",
    "        geometry = odl.tomo.FanBeamGeometry(angles, lines, source_radius, detector_radius)\n",
    "        output_shape = (int(360), int(512/factor_lines))\n",
    "        \n",
    "    # domain = odl.uniform_discr(min_domain_corner, max_domain_corner, output_shape, dtype=dtype)\n",
    "\n",
    "    ray_transform = odl.tomo.RayTransform(domain, geometry, impl=device)\n",
    "\n",
    "    return domain, geometry, ray_transform, output_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then there is couple of parameters and such. <br>\n",
    "For a device it is good to use CUDA if available. Not necessary when not training but still."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "path = r'c:\\Users\\Antti\\Documents\\DL'\n",
    "amount_of_images = 2\n",
    "mean = 0\n",
    "noise_percentage = 0.05\n",
    "\n",
    "\n",
    "loss_test = nn.MSELoss()\n",
    "\n",
    "def psnr(loss):\n",
    "    \n",
    "    psnr = 10 * np.log10(1.0 / loss+1e-10)\n",
    "    \n",
    "    return psnr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next one imports the image(s) and does some tricks with the data to get everything to roll. Also ODL operators are defined here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = get_images(r'c:\\Users\\Antti\\Documents\\DL\\walnuts', amount_of_images, scale_number=2)\n",
    "images = np.array(images, dtype='float32')\n",
    "images = torch.from_numpy(images).float().to(device)\n",
    "\n",
    "shape = (np.shape(images)[1], np.shape(images)[2])\n",
    "domain, geometry, ray_transform, output_shape = geometry_and_ray_trafo(setup='full', shape=shape, device=device, factor_lines = 2)\n",
    "fbp_operator = odl.tomo.analytic.filtered_back_projection.fbp_op(ray_transform, padding=1)\n",
    "\n",
    "### Using odl functions to make odl operators into PyTorch modules\n",
    "ray_transform_module = OperatorModule(ray_transform).to(device)\n",
    "adjoint_operator_module = OperatorModule(ray_transform.adjoint).to(device)\n",
    "fbp_operator_module = OperatorModule(fbp_operator).to(device)\n",
    "\n",
    "### Making sinograms from the images using Radon transform module\n",
    "sinograms = ray_transform_module(images) #.cpu().detach().numpy()\n",
    "\n",
    "### Allocating used tensors\n",
    "noisy_sinograms = torch.zeros((sinograms.shape[0], ) + output_shape).cpu().detach().numpy()\n",
    "rec_images = torch.zeros((sinograms.shape[0], ) + shape)\n",
    "\n",
    "### Adding Gaussian noise to the sinograms.\n",
    "for k in range(amount_of_images):\n",
    "    sinogram_k = sinograms[k,:,:].cpu().detach().numpy()\n",
    "    noise = np.random.normal(mean, sinogram_k.std(), sinogram_k.shape) * noise_percentage\n",
    "    noisy_sinograms[k,:,:] = sinogram_k + noise\n",
    "\n",
    "noisy_sinograms = np.array(noisy_sinograms, dtype='float32')\n",
    "noisy_sinograms = torch.from_numpy(noisy_sinograms).float().to(device)\n",
    "\n",
    "rec_images = fbp_operator_module(noisy_sinograms)\n",
    "rec_images = rec_images[:,None,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FBP + U-Net denoising <br>\n",
    "Here one loads and uses the U-Net denoising algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNet = UNet(in_channels=1, out_channels=1).to(device)\n",
    "UNet.load_state_dict(torch.load(path+'/UNet1_005.pth', map_location=device))\n",
    "\n",
    "UNet.eval()\n",
    "\n",
    "UNet_reco = UNet(rec_images)\n",
    "\n",
    "MSE = loss_test(images[0,:,:], UNet_reco[0,0,:,:]).cpu().detach().numpy()\n",
    "print(f'{MSE:.2e}')\n",
    "print(f'PSNR = {psnr(MSE):.2f} dB')\n",
    "\n",
    "plt.figure()\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(rec_images[0,0,:,:].cpu().detach().numpy())\n",
    "plt.gca().set_title('Noisy image')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(UNet_reco[0,0,:,:].cpu().detach().numpy())\n",
    "plt.gca().set_title('U-Net reconstruction')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(images[0,:,:].cpu().detach().numpy())\n",
    "plt.gca().set_title('Ground truth')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGS <br>\n",
    "Then is the LGS. Better result than with the U-Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sinograms = torch.from_numpy(sinograms).float().to(device)\n",
    "sinograms = sinograms[:,None,:,:]\n",
    "noisy_sinograms = noisy_sinograms[:,None,:,:]\n",
    "# print(rec_images.shape)\n",
    "# print(sinograms.shape)\n",
    "\n",
    "LGS = LGS(adjoint_operator_module, ray_transform_module, \\\n",
    "          noisy_sinograms, rec_images, in_channels=2, out_channels=1, step_length=0.1, n_iter=5).to(device)\n",
    "LGS.load_state_dict(torch.load(path+'/LGS1_005.pth', map_location=device))\n",
    "\n",
    "LGS.eval()\n",
    "\n",
    "LGS_reco, _ = LGS(rec_images[:,:,:], noisy_sinograms[:,:,:])\n",
    "\n",
    "MSE = loss_test(images[0,:,:], LGS_reco[0,0,:,:]).cpu().detach().numpy()\n",
    "print(f'{MSE:.2e}')\n",
    "print(f'PSNR = {psnr(MSE):.2f} dB')\n",
    "\n",
    "# print('reco', type(reco))\n",
    "\n",
    "plt.figure()\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(rec_images[0,0,:,:].cpu().detach().numpy())\n",
    "plt.gca().set_title('Noisy image')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(LGS_reco[0,0,:,:].cpu().detach().numpy())\n",
    "plt.gca().set_title('LGS reconstruction')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(images[0,:,:].cpu().detach().numpy())\n",
    "plt.gca().set_title('Ground truth')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LPD <br>\n",
    "Finally the LPD. LPD did perform a little bit better in training, but when used here sometimes the LGS is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator_norm = odl.power_method_opnorm(ray_transform)\n",
    "\n",
    "LPD = LPD(ray_transform_module, adjoint_operator_module, operator_norm, n_iter=10, device=device)\n",
    "LPD.load_state_dict(torch.load(path+'/LPD1_005.pth', map_location=device))\n",
    "\n",
    "LPD.eval()\n",
    "\n",
    "LPD_reco = LPD(rec_images[:,:,:], noisy_sinograms[:,:,:])\n",
    "\n",
    "MSE = loss_test(images[0,:,:], LPD_reco[0,0,:,:]).cpu().detach().numpy()\n",
    "print(f'{MSE:.2e}')\n",
    "print(f'PSNR = {psnr(MSE):.2f} dB')\n",
    "\n",
    "plt.figure()\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(rec_images[0,0,:,:].cpu().detach().numpy())\n",
    "plt.gca().set_title('Noisy image')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(LPD_reco[0,0,:,:].cpu().detach().numpy())\n",
    "plt.gca().set_title('LPD reconstruction')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(images[0,:,:].cpu().detach().numpy())\n",
    "plt.gca().set_title('Ground truth')\n",
    "# plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last thing is the comparison of all the reconstructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_number = 1 # Must be less than or equal to amount of images\n",
    "\n",
    "plt.figure()\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(UNet_reco[image_number-1,0,:,:].cpu().detach().numpy())\n",
    "plt.gca().set_title('U-Net')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(LGS_reco[image_number-1,0,:,:].cpu().detach().numpy())\n",
    "plt.gca().set_title('LGS')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(LPD_reco[image_number-1,0,:,:].cpu().detach().numpy())\n",
    "plt.gca().set_title('LPD')\n",
    "# plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
