{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical image denoising algorithms for autumn school in University of Cambridge\n",
    "\n",
    "In this notebook there are five different image denoising algorithms which have been coded mostly with a Python library called \"Operator Discretization Library (ODL)\". <br>\n",
    "Before iterative algorithms there is a little bit of mathematical background on what is happening in coming code section and hopefully it helps to understand the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The packages needed for this notebook to run through.\n",
    "\n",
    "import odl\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from select_image import select_image\n",
    "# from select_geometry import geometry_and_ray_trafo\n",
    "# from select_algorithm import algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here one loads the image which is used in these classical algorithms. \n",
    "\n",
    "### Define your own path to the image.\n",
    "path = r'C:\\Users\\Antti\\Downloads\\usable_full_AGD_50_000257_19.tiff'\n",
    "\n",
    "### Load the image.\n",
    "image = cv.imread(path, cv.IMREAD_UNCHANGED)\n",
    "image = image[90:410, 90:410]\n",
    "# image = image[0:320:factor, 0:320:factor]\n",
    "\n",
    "### Normalizing the image and taking its shape.\n",
    "image = image / np.max(np.max(image))\n",
    "shape = np.shape(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fan beam geometry and ray transform:\n",
    "\n",
    "In the next code section one defines a fan beam geometry which simulates the geometry of the CT-scan. <br>\n",
    "After the geometry is defined, one defines a domain for ray transform and ray transform itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### There is couple of parameters:\n",
    "\n",
    "### What kind measurement environment one wants to choose.\n",
    "### Possible options are 'full', 'sparse', 'limited'.\n",
    "setup = 'sparse'\n",
    "\n",
    "### Factor down amount of the detection lines, must be int.\n",
    "factor_lines = 1\n",
    "\n",
    "### Radius from the source to object.\n",
    "source_radius = 2\n",
    "\n",
    "### Radius from the object to detector.\n",
    "detector_radius = 1\n",
    "\n",
    "if setup == 'full':\n",
    "    angles = odl.uniform_partition(0, 2*np.pi, 360)\n",
    "    lines = odl.uniform_partition(-np.pi, np.pi, int(1024/factor_lines))\n",
    "    geometry = odl.tomo.FanBeamGeometry(angles, lines, source_radius, detector_radius)\n",
    "elif setup == 'sparse':\n",
    "    angle_measurements = 50\n",
    "    line_measurements = int(1024/factor_lines)\n",
    "    angles = odl.uniform_partition(0, 2*np.pi, angle_measurements)\n",
    "    lines = odl.uniform_partition(-1*np.pi, np.pi, line_measurements)\n",
    "    geometry = odl.tomo.FanBeamGeometry(angles, lines, source_radius, detector_radius)\n",
    "elif setup == 'limited':\n",
    "    starting_angle = 0\n",
    "    final_angle = np.pi * 1/2\n",
    "    angles = odl.uniform_partition(starting_angle, final_angle, 360)\n",
    "    lines = odl.uniform_partition(-1*np.pi, np.pi, int(1024/factor_lines))\n",
    "    geometry = odl.tomo.FanBeamGeometry(angles, lines, source_radius, detector_radius)\n",
    "\n",
    "\n",
    "### The domain is defined here, there is couple of parameters:\n",
    "\n",
    "### Imagine a box in 2D-plane with this parameter being the most southwest point of the box.\n",
    "min_domain_corner = [-1,-1]\n",
    "\n",
    "### Imagine a box in 2D-plane with this parameter being the most northeast point of the box.\n",
    "max_domain_corner = [1,1]\n",
    "\n",
    "### Number of samples per axis.\n",
    "shape = shape\n",
    "\n",
    "### Data type \n",
    "dtype = 'float'\n",
    "\n",
    "domain = odl.uniform_discr(min_domain_corner, max_domain_corner, shape=shape, dtype=dtype)\n",
    "\n",
    "### The ray transform is defined here\n",
    "\n",
    "device = 'astra_cpu'\n",
    "\n",
    "ray_transform = odl.tomo.RayTransform(domain, geometry, impl=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sinogram and noise\n",
    "\n",
    "Next up is using the ray transform to obtain a sinogram from the image. <br>\n",
    "After that one can/will add there noise, in this notebook Gaussian noise is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First convert image into ODL form\n",
    "image = domain.element(image)\n",
    "\n",
    "### Use ray transform to the image to obtain sinogram\n",
    "sinogram = ray_transform(image)\n",
    "\n",
    "### Parameters for the Gaussian noise\n",
    "mean = 0.0\n",
    "variance = 0.0002\n",
    "sigma = variance ** 0.5\n",
    "\n",
    "### Create noisy sinogram\n",
    "noisy_sinogram = sinogram + np.random.normal(mean, sigma, size=(np.shape(sinogram)[0], np.shape(sinogram)[1]))\n",
    "noisy_sinogram = np.maximum(noisy_sinogram,0)\n",
    "image.show('Ground truth')\n",
    "sinogram.show('Clear sinogram')\n",
    "noisy_sinogram.show('Noisy sinogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction methods\n",
    "\n",
    "Last sections contains different kind of reconstruction algorithms. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered Back Projection (FBP):\n",
    "\n",
    "This is the approximate inverse of ray transform. <br>\n",
    "This is easy to define in the ODL as one can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### There is function in ODL to create FBP operator:\n",
    "FBP_operator = odl.tomo.analytic.filtered_back_projection.fbp_op(ray_trafo=ray_transform, padding=1)\n",
    "\n",
    "### One just applies the noisy sinogram with just defined FBP operator and gets a reconstruction out.\n",
    "reconstruction = FBP_operator(noisy_sinogram)\n",
    "\n",
    "### Because in these sections the images are plotted in ODL domain the next thing is needed:\n",
    "reconstruction = domain.element(reconstruction)\n",
    "\n",
    "### Plotting the reconstructed image\n",
    "reconstruction.show('reconstruction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tikhonov regularization\n",
    "\n",
    "This is the first iterative algorithm. It is based on a regularization theory and it is a minimization problem formulated as <br>\n",
    "$$\n",
    "\\argmin_x \\mathcal{E}(x) = \\argmin_{x} \\{ ||Ax - y||^2_2 + \\lambda ||Bx||^2_2 \\}\n",
    "$$\n",
    "Above minimization problem can be understood such that the final answer $x$ should give a good balance between small residual in the first norm and a small value in $L^2$-norm. <br> \n",
    "That minimization problem can be solved iteratively with gradient descent. For one to solve the iterative step, the first thing to do is take a derivative of the minimization problem with respect to $x$ and setting it equal to zero. <br>\n",
    "That then yields an equation which looks like \n",
    "$$\n",
    "\\nabla_x \\mathcal{E}(x) = (A^T A + \\lambda B^T B)x - A^T y\n",
    "$$\n",
    "In this case we will also set that $B = I$ and that then gives \n",
    "$$\n",
    "\\nabla_x \\mathcal{E}(x) = (A^T A + \\lambda I)x - A^T y = Tx - b\n",
    "$$\n",
    "That equation is now used in the gradient descent such that the iterative step is given as\n",
    "$$\n",
    "x_{i+1} = x_i - \\beta \\nabla_x \\mathcal{E}(x_i) = x_i - \\beta (T x_i - b)\n",
    "$$\n",
    "Below there is then a code with this formulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Renaming ray transform as \"operator\"\n",
    "operator = ray_transform\n",
    "\n",
    "### Defining step size \"beta\" which is depends on the value of the operator norm\n",
    "operator_norm = 1.1 * odl.power_method_opnorm(operator)\n",
    "beta = 1/(operator_norm**2)\n",
    "\n",
    "### This is how one defines ideneity operator in ODL\n",
    "id = odl.IdentityOperator(domain)\n",
    "\n",
    "### Lambda parameter\n",
    "lam = 5\n",
    "\n",
    "### Operator \"T\" defined just as written in equation above\n",
    "T = operator.adjoint * operator + lam *  id.adjoint * id\n",
    "\n",
    "# Tgrad = operator.adjoint * operator\n",
    "\n",
    "### Evaluating \"b\" like written above\n",
    "b = operator.adjoint(noisy_sinogram)\n",
    "\n",
    "### Amount of iterative steps\n",
    "iterations = 200\n",
    "\n",
    "### Starting point f_0 is zero matrix\n",
    "f_new = domain.zero()\n",
    "\n",
    "### Here is the iterative loop\n",
    "for k in range(iterations):\n",
    "    if k % 50 == 0:\n",
    "        print(f'Iteration {k}/{iterations}')\n",
    "    \n",
    "    ### Iterative step\n",
    "    f_old = f_new\n",
    "    f_new = f_old - beta * (T(f_old) - b)\n",
    "    # f_old = f_new\n",
    "\n",
    "tikhonov_reconstruction = domain.element(f_new)\n",
    "tikhonov_reconstruction.show('Tikhonov regularization reconstruction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other option is to smoothly approximate TV-regularization term with some constant $\\beta > 0$ such that it get a form\n",
    "$$\n",
    "\\mathcal{R}(x) = || |\\nabla x|_\\beta ||_1 = \\left\\| \\sqrt{\\sum_i (\\partial_i x)^2 + \\beta^2} \\right\\|_1\n",
    "$$\n",
    "which is now differentiable. <br>\n",
    "The gradient of the regularizer is given by\n",
    "$$\n",
    "\\nabla_x \\mathcal{R}(x) = \\nabla^T \\cdot \\left( \\frac{\\nabla x}{\\sqrt{\\sum_i (\\partial_i x)² + \\beta^2}} \\right)\n",
    "$$\n",
    "Then a gradient of the data fidality term is\n",
    "$$\n",
    "\\nabla_x [ || Ax - y ||_2 ] = 2 A^* (Ax - y) = T_1 (Ax -y) = T_2 x - T_1 y = T_2 x - b\n",
    "$$\n",
    "Now one can use the basic gradient descent algorithm to obtain reconstruction. Code implementation is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First one defines the gradient over the domain of the problem\n",
    "gradient = odl.Gradient(domain)\n",
    "\n",
    "### Defining operators given above\n",
    "T_1 = 2*operator.adjoint\n",
    "T_2 = T_1*operator\n",
    "\n",
    "\n",
    "### Evaluating b = T_1 * g\n",
    "b = T_1(noisy_sinogram)\n",
    "\n",
    "### Initializing f to zero\n",
    "f_new =  operator.adjoint(noisy_sinogram) / operator_norm\n",
    "\n",
    "### Amount of iterations\n",
    "iterations = 1000\n",
    "\n",
    "### Parameters\n",
    "step_size = 1e-4\n",
    "max_step = 1/ (operator_norm**2)\n",
    "beta = 1e-6 \n",
    "lam = 1e-3\n",
    "\n",
    "denomi = np.sqrt(gradient(f_new)**2 + beta)\n",
    "division = gradient(f_new) / denomi\n",
    "gradCur = (T_2(f_new) - b) + lam * gradient.adjoint(division)\n",
    "\n",
    "for k in range(iterations):\n",
    "    if k % 50 == 0:\n",
    "        print(f'Iteration {k}/{iterations}')\n",
    "        smoothed_reconstruction = domain.element(f_new)\n",
    "        smoothed_reconstruction.show('Smoothed TV regularization reconstruction')\n",
    "        # grad.show('gradient')\n",
    "        plt.show()\n",
    "    \n",
    "    ### Iterative step\n",
    "    f_old = f_new\n",
    "    grad_old=gradCur\n",
    "    f_new = np.maximum(f_new - step_size * gradCur,0)\n",
    " \n",
    "    denomi = np.sqrt(gradient(f_new)**2 + beta)\n",
    "    division = gradient(f_new) / denomi\n",
    "    gradCur = (T_2(f_new) - b) + lam * gradient.adjoint(division)\n",
    "\n",
    "\n",
    "    step_size =np.minimum(np.sum(np.multiply(f_new-f_old, f_new-f_old)) / np.sum(np.multiply(f_new-f_old,gradCur - grad_old)),max_step)\n",
    "    \n",
    "    \n",
    "\n",
    "const = domain.one() * (np.sqrt(np.sum(np.sum(gradient(f_old)**2)) + beta))\n",
    "division = gradient(f_old) / const\n",
    "# grad = (T_2(f_old) - b) - lam * divergence(division)\n",
    "# grad = domain.element(grad)\n",
    "smoothed_reconstruction = domain.element(f_new)\n",
    "smoothed_reconstruction.show('Smoothed TV regularization reconstruction')\n",
    "# grad.show('gradient')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
